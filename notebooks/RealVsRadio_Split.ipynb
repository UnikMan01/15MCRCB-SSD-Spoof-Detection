{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23bc3cfd-30ea-4d87-a578-79e4ebd4c41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Classes: 30\n",
      "['Barishal', 'Barishal_radio', 'Chapai', 'Chapai_radio', 'Chittagong', 'Chittagong_radio', 'Habiganj', 'Habiganj_radio', 'Kustia', 'Kustia_radio', 'Naoga', 'Naoga_radio', 'Narail', 'Narail_radio', 'Narsingdi', 'Narsingdi_radio', 'Rajshahi', 'Rajshahi_radio', 'Rangpur', 'Rangpur_radio', 'Sandwip', 'Sandwip_radio', 'Sylhet', 'Sylhet_radio', 'Tangail', 'Tangail_radio', 'kishoreganj', 'kishoreganj_radio', 'pabna', 'pabna_radio']\n",
      "train set: 27936 files\n",
      "val set: 5994 files\n",
      "test set: 6010 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AASISTLite(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (proj): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (temporal): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AttentivePool(\n",
      "    (attn): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [23:02<00:00,  1.26it/s]\n",
      "Epoch 1/30 [val]: 100%|██████████████████████████████████████████████████████████████| 375/375 [04:18<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 1.3952 Acc 0.4821 | Val Loss 0.9981 Acc 0.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [25:24<00:00,  1.15it/s]\n",
      "Epoch 2/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 146.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss 0.8907 Acc 0.6519 | Val Loss 0.7455 Acc 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [22:02<00:00,  1.32it/s]\n",
      "Epoch 3/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 153.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss 0.7159 Acc 0.7143 | Val Loss 0.6240 Acc 0.7794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [18:48<00:00,  1.55it/s]\n",
      "Epoch 4/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 149.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss 0.5863 Acc 0.7676 | Val Loss 0.5794 Acc 0.8005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [19:18<00:00,  1.51it/s]\n",
      "Epoch 5/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 136.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss 0.5088 Acc 0.7956 | Val Loss 0.4815 Acc 0.8393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [24:49<00:00,  1.17it/s]\n",
      "Epoch 6/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 153.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss 0.4356 Acc 0.8242 | Val Loss 0.4256 Acc 0.8567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [28:32<00:00,  1.02it/s]\n",
      "Epoch 7/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 152.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss 0.3812 Acc 0.8458 | Val Loss 0.4333 Acc 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [26:42<00:00,  1.09it/s]\n",
      "Epoch 8/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 141.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss 0.3400 Acc 0.8620 | Val Loss 0.4585 Acc 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [train]: 100%|██████████████████████████████████████████████████████████| 1746/1746 [23:02<00:00,  1.26it/s]\n",
      "Epoch 9/30 [val]: 100%|█████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 147.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss 0.3067 Acc 0.8782 | Val Loss 0.3683 Acc 0.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:27<00:00,  1.42it/s]\n",
      "Epoch 10/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 155.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss 0.2742 Acc 0.8860 | Val Loss 0.3597 Acc 0.8819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:23<00:00,  1.43it/s]\n",
      "Epoch 11/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 142.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss 0.2482 Acc 0.9003 | Val Loss 0.3386 Acc 0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:33<00:00,  1.42it/s]\n",
      "Epoch 12/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 148.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss 0.2233 Acc 0.9105 | Val Loss 0.3193 Acc 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:20<00:00,  1.43it/s]\n",
      "Epoch 13/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 152.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss 0.2086 Acc 0.9175 | Val Loss 0.3392 Acc 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:19<00:00,  1.43it/s]\n",
      "Epoch 14/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 151.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss 0.1904 Acc 0.9249 | Val Loss 0.3362 Acc 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:23<00:00,  1.43it/s]\n",
      "Epoch 15/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 152.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss 0.1813 Acc 0.9289 | Val Loss 0.3034 Acc 0.9112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:24<00:00,  1.43it/s]\n",
      "Epoch 16/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 154.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss 0.1588 Acc 0.9369 | Val Loss 0.3051 Acc 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:45<00:00,  1.40it/s]\n",
      "Epoch 17/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 148.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss 0.1559 Acc 0.9401 | Val Loss 0.3072 Acc 0.9146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:51<00:00,  1.39it/s]\n",
      "Epoch 18/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 149.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss 0.1469 Acc 0.9429 | Val Loss 0.3044 Acc 0.9174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [22:10<00:00,  1.31it/s]\n",
      "Epoch 19/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 156.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss 0.1333 Acc 0.9506 | Val Loss 0.3158 Acc 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [23:08<00:00,  1.26it/s]\n",
      "Epoch 20/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 151.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss 0.1277 Acc 0.9528 | Val Loss 0.3011 Acc 0.9169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:51<00:00,  1.39it/s]\n",
      "Epoch 21/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 152.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss 0.1234 Acc 0.9550 | Val Loss 0.3233 Acc 0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:49<00:00,  1.40it/s]\n",
      "Epoch 22/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 151.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss 0.1152 Acc 0.9585 | Val Loss 0.2773 Acc 0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [21:04<00:00,  1.38it/s]\n",
      "Epoch 23/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 146.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss 0.1134 Acc 0.9593 | Val Loss 0.3354 Acc 0.9203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [20:47<00:00,  1.40it/s]\n",
      "Epoch 24/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 156.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss 0.1067 Acc 0.9622 | Val Loss 0.3039 Acc 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [21:37<00:00,  1.35it/s]\n",
      "Epoch 25/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 151.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss 0.1068 Acc 0.9612 | Val Loss 0.3381 Acc 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [22:02<00:00,  1.32it/s]\n",
      "Epoch 26/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 144.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss 0.0459 Acc 0.9819 | Val Loss 0.2646 Acc 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [23:16<00:00,  1.25it/s]\n",
      "Epoch 27/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 148.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss 0.0432 Acc 0.9837 | Val Loss 0.2975 Acc 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [35:08<00:00,  1.21s/it]\n",
      "Epoch 28/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:03<00:00, 109.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss 0.0418 Acc 0.9861 | Val Loss 0.2826 Acc 0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [48:54<00:00,  1.68s/it]\n",
      "Epoch 29/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:03<00:00, 110.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss 0.0368 Acc 0.9864 | Val Loss 0.2980 Acc 0.9433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [train]: 100%|█████████████████████████████████████████████████████████| 1746/1746 [50:48<00:00,  1.75s/it]\n",
      "Epoch 30/30 [val]: 100%|████████████████████████████████████████████████████████████| 375/375 [00:03<00:00, 111.65it/s]\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_28684\\2542268671.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_aasist_lite.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss 0.0363 Acc 0.9873 | Val Loss 0.2964 Acc 0.9443\n",
      "Training done. Best Val Acc: 0.9442776109442776\n",
      "Saved best weights to best_aasist_lite.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████| 6010/6010 [1:14:39<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CLASSIFICATION REPORT ================\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Barishal     0.9701    0.9559    0.9630       136\n",
      "   Barishal_radio     0.8507    0.8382    0.8444       136\n",
      "           Chapai     1.0000    0.9868    0.9933       151\n",
      "     Chapai_radio     0.9869    1.0000    0.9934       151\n",
      "       Chittagong     0.9664    0.9664    0.9664       238\n",
      " Chittagong_radio     0.8970    0.8782    0.8875       238\n",
      "         Habiganj     0.8968    0.8742    0.8854       159\n",
      "   Habiganj_radio     0.7914    0.8113    0.8012       159\n",
      "           Kustia     1.0000    1.0000    1.0000       151\n",
      "     Kustia_radio     0.9934    1.0000    0.9967       151\n",
      "            Naoga     1.0000    0.9934    0.9967       151\n",
      "      Naoga_radio     1.0000    1.0000    1.0000       151\n",
      "           Narail     0.9722    0.9761    0.9742       251\n",
      "     Narail_radio     0.8731    0.9044    0.8885       251\n",
      "        Narsingdi     0.9570    0.9570    0.9570       186\n",
      "  Narsingdi_radio     0.9027    0.8978    0.9003       186\n",
      "         Rajshahi     1.0000    0.9931    0.9965       145\n",
      "   Rajshahi_radio     0.9797    1.0000    0.9898       145\n",
      "          Rangpur     0.9714    0.9659    0.9687       176\n",
      "    Rangpur_radio     0.9704    0.9318    0.9507       176\n",
      "          Sandwip     0.9827    0.9605    0.9714       177\n",
      "    Sandwip_radio     0.9119    0.8192    0.8631       177\n",
      "           Sylhet     0.9364    0.9632    0.9496       489\n",
      "     Sylhet_radio     0.8552    0.9059    0.8798       489\n",
      "          Tangail     0.9818    0.9643    0.9730       168\n",
      "    Tangail_radio     0.8470    0.9226    0.8832       168\n",
      "      kishoreganj     0.9783    0.9747    0.9765       277\n",
      "kishoreganj_radio     0.9605    0.8773    0.9170       277\n",
      "            pabna     1.0000    1.0000    1.0000       150\n",
      "      pabna_radio     1.0000    0.9867    0.9933       150\n",
      "\n",
      "         accuracy                         0.9403      6010\n",
      "        macro avg     0.9478    0.9435    0.9453      6010\n",
      "     weighted avg     0.9411    0.9403    0.9404      6010\n",
      "\n",
      "\n",
      "Saved figures:\n",
      "confusion_matrix.png, roc_multiclass.png, pr_multiclass.png, loss_curve.png, acc_curve.png\n",
      "waveform.png, spectrogram.png, chromagram.png, pca_embeddings.png, tsne_embeddings.png\n",
      "Best model: best_aasist_lite.pth\n"
     ]
    }
   ],
   "source": [
    "# ===================== AASIST-Lite (Spectro-Temporal) FULL TRAIN+EVAL CODE =====================\n",
    "# Works with your folder structure:\n",
    "# D:\\RealVsMonster_Split\\train\\<class>\\audio.*\n",
    "# D:\\RealVsMonster_Split\\val\\<class>\\audio.*\n",
    "# D:\\RealVsMonster_Split\\test\\<class>\\audio.*\n",
    "#\n",
    "# Output:\n",
    "# - best_aasist_lite.pth\n",
    "# - confusion_matrix.png\n",
    "# - roc_multiclass.png\n",
    "# - pr_multiclass.png\n",
    "# - loss_curve.png\n",
    "# - acc_curve.png\n",
    "# - waveform.png / spectrogram.png / chromagram.png\n",
    "# - pca_embeddings.png / tsne_embeddings.png\n",
    "# - classification report printed in console\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATASET_ROOT = r\"D:\\RealVsRadio_Split\"\n",
    "SAMPLE_RATE  = 16000\n",
    "\n",
    "# Feature: 2-channel -> [LogMel, Linear-Fbank(log)]  (spectral)\n",
    "N_MELS       = 64\n",
    "N_LINFB      = 64\n",
    "N_FFT        = 1024\n",
    "HOP_LENGTH   = 256\n",
    "MAX_FRAMES   = 256\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE   = 16\n",
    "EPOCHS       = 30\n",
    "LR           = 2e-4\n",
    "RANDOM_SEED  = 42\n",
    "\n",
    "# SpecAugment\n",
    "USE_SPECAUG      = True\n",
    "TIME_MASK_PARAM  = 24\n",
    "FREQ_MASK_PARAM  = 6\n",
    "\n",
    "# Audio safety\n",
    "MIN_AUDIO_SAMPLES = 2048\n",
    "MIN_RMS = 1e-4\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------- CLASS NAMES ----------------\n",
    "train_base = os.path.join(DATASET_ROOT, \"train\")\n",
    "CLASS_NAMES = sorted([d for d in os.listdir(train_base) if os.path.isdir(os.path.join(train_base, d))])\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(\"Classes:\", NUM_CLASSES)\n",
    "print(CLASS_NAMES)\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def pad_trunc_2d(X, max_frames):\n",
    "    # X: (F, T)\n",
    "    if X.shape[1] < max_frames:\n",
    "        pad = np.zeros((X.shape[0], max_frames - X.shape[1]), dtype=np.float32)\n",
    "        X = np.concatenate([X, pad], axis=1)\n",
    "    else:\n",
    "        X = X[:, :max_frames]\n",
    "    return X\n",
    "\n",
    "def zscore_norm(X, eps=1e-6):\n",
    "    mu = float(X.mean())\n",
    "    std = float(X.std())\n",
    "    return (X - mu) / (std + eps)\n",
    "\n",
    "def safe_load_and_trim(path):\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
    "    y, _ = librosa.effects.trim(y, top_db=30)\n",
    "\n",
    "    if y is None or len(y) < MIN_AUDIO_SAMPLES:\n",
    "        return None, sr\n",
    "\n",
    "    rms = float(np.sqrt(np.mean(y**2) + 1e-12))\n",
    "    if rms < MIN_RMS:\n",
    "        return None, sr\n",
    "\n",
    "    return y, sr\n",
    "\n",
    "# ---------------- FEATURE EXTRACTION ----------------\n",
    "def extract_logmel(y, sr):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH, power=2.0\n",
    "    )\n",
    "    mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel = zscore_norm(mel).astype(np.float32)\n",
    "    mel = pad_trunc_2d(mel, MAX_FRAMES)\n",
    "    return mel  # (64, T)\n",
    "\n",
    "def extract_log_linear_fbank(y, sr):\n",
    "    \"\"\"\n",
    "    Manual linear-frequency filterbank energies (log)  (no librosa.filters.linear dependency)\n",
    "    \"\"\"\n",
    "    S = np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH))**2  # (F, T)\n",
    "    F_bins = S.shape[0]\n",
    "\n",
    "    freqs = np.linspace(0, sr/2, F_bins, dtype=np.float32)\n",
    "    edges = np.linspace(0, sr/2, N_LINFB + 2, dtype=np.float32)\n",
    "\n",
    "    fb = np.zeros((N_LINFB, F_bins), dtype=np.float32)\n",
    "    for m in range(N_LINFB):\n",
    "        f_left, f_center, f_right = edges[m], edges[m+1], edges[m+2]\n",
    "        left  = (freqs - f_left) / (f_center - f_left + 1e-9)\n",
    "        right = (f_right - freqs) / (f_right - f_center + 1e-9)\n",
    "        fb[m] = np.maximum(0.0, np.minimum(left, right))\n",
    "\n",
    "    E = np.dot(fb, S) + 1e-8\n",
    "    E = np.log(E)\n",
    "\n",
    "    E = zscore_norm(E).astype(np.float32)\n",
    "    E = pad_trunc_2d(E, MAX_FRAMES)\n",
    "    return E  # (64, T)\n",
    "\n",
    "def extract_features(path):\n",
    "    y, sr = safe_load_and_trim(path)\n",
    "    if y is None:\n",
    "        mel = np.zeros((N_MELS, MAX_FRAMES), dtype=np.float32)\n",
    "        lfb = np.zeros((N_LINFB, MAX_FRAMES), dtype=np.float32)\n",
    "    else:\n",
    "        mel = extract_logmel(y, sr)\n",
    "        lfb = extract_log_linear_fbank(y, sr)\n",
    "    X = np.stack([mel, lfb], axis=0).astype(np.float32)  # (2, 64, T)\n",
    "    return X\n",
    "\n",
    "# ---------------- SPECAUGMENT ----------------\n",
    "def spec_augment(x, time_mask_param=24, freq_mask_param=6):\n",
    "    # x: torch tensor (C,F,T) ; masks apply all channels\n",
    "    if not USE_SPECAUG:\n",
    "        return x\n",
    "    C, F, T = x.shape\n",
    "\n",
    "    f = random.randint(0, min(freq_mask_param, F))\n",
    "    f0 = random.randint(0, max(0, F - f))\n",
    "    if f > 0:\n",
    "        x[:, f0:f0+f, :] = 0\n",
    "\n",
    "    t = random.randint(0, min(time_mask_param, T))\n",
    "    t0 = random.randint(0, max(0, T - t))\n",
    "    if t > 0:\n",
    "        x[:, :, t0:t0+t] = 0\n",
    "\n",
    "    return x\n",
    "\n",
    "# ---------------- DATASET ----------------\n",
    "class SpecDataset(Dataset):\n",
    "    def __init__(self, root, split):\n",
    "        base = os.path.join(root, split)\n",
    "        self.split = split\n",
    "        self.paths, self.labels = [], []\n",
    "        self.cls_to_idx = {c: i for i, c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "        for cls in CLASS_NAMES:\n",
    "            folder = os.path.join(base, cls)\n",
    "            if not os.path.isdir(folder):\n",
    "                continue\n",
    "            for f in os.listdir(folder):\n",
    "                if f.lower().endswith((\".mp3\", \".wav\", \".ogg\", \".flac\", \".m4a\")):\n",
    "                    self.paths.append(os.path.join(folder, f))\n",
    "                    self.labels.append(self.cls_to_idx[cls])\n",
    "\n",
    "        print(f\"{split} set: {len(self.paths)} files\")\n",
    "        self.cache = {}  # cache val/test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.split != \"train\" and path in self.cache:\n",
    "            feat = self.cache[path]\n",
    "        else:\n",
    "            feat = extract_features(path)\n",
    "            if self.split != \"train\":\n",
    "                self.cache[path] = feat\n",
    "\n",
    "        x = torch.tensor(feat)  # (2,64,T)\n",
    "        if self.split == \"train\":\n",
    "            x = spec_augment(x, TIME_MASK_PARAM, FREQ_MASK_PARAM)\n",
    "\n",
    "        return x, torch.tensor(label, dtype=torch.long), path\n",
    "\n",
    "train_ds = SpecDataset(DATASET_ROOT, \"train\")\n",
    "val_ds   = SpecDataset(DATASET_ROOT, \"val\")\n",
    "test_ds  = SpecDataset(DATASET_ROOT, \"test\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=1,          shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ---------------- MODEL (AASIST-Lite): CNN(spectral) + Transformer(temporal) + AttnPool ----------------\n",
    "class AttentivePool(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(d, d//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d//2, 1)\n",
    "        )\n",
    "    def forward(self, x):   # (B,T,D)\n",
    "        w = torch.softmax(self.attn(x), dim=1)  # (B,T,1)\n",
    "        return (w * x).sum(dim=1)               # (B,D)\n",
    "\n",
    "class AASISTLite(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: (B, 2, 64, T)\n",
    "    CNN -> spectral patterns\n",
    "    Transformer -> temporal patterns\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, d_model=256, nhead=4, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),  # F/2, T/2\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),  # F/4, T/4\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),  # F/8, T/8\n",
    "        )\n",
    "\n",
    "        f_after = N_MELS // 8  # 64 -> 8\n",
    "        self.proj = nn.Linear(128 * f_after, d_model)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, batch_first=True, activation=\"gelu\", norm_first=True\n",
    "        )\n",
    "        self.temporal = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        self.pool = AttentivePool(d_model)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.cnn(x)                      # (B,128,F',T')\n",
    "        B, C, F, T = z.shape\n",
    "        z = z.permute(0, 3, 1, 2).contiguous()  # (B,T,C,F)\n",
    "        z = z.view(B, T, C*F)                   # (B,T,128*F')\n",
    "        z = self.proj(z)                        # (B,T,d_model)\n",
    "\n",
    "        z = self.temporal(z)                    # (B,T,d_model)  (temporal features)\n",
    "        emb = self.pool(z)                      # (B,d_model)\n",
    "        logits = self.head(emb)                 # (B,num_classes)\n",
    "        return logits, emb\n",
    "\n",
    "model = AASISTLite(num_classes=NUM_CLASSES).to(device)\n",
    "print(model)\n",
    "\n",
    "# ---------------- LOSS/OPT ----------------\n",
    "counts = np.bincount(train_ds.labels, minlength=NUM_CLASSES).astype(np.float32)\n",
    "w = (counts.sum() / (counts + 1e-6))\n",
    "w = w / w.mean()\n",
    "class_weights = torch.tensor(w, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "use_amp = (device.type == \"cuda\")\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "\n",
    "def acc_from_logits(logits, y):\n",
    "    return (torch.argmax(logits, 1) == y).float().mean().item()\n",
    "\n",
    "# ---------------- TRAIN ----------------\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "best_val = -1.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    tr_loss_sum, tr_acc_sum, tr_n = 0.0, 0.0, 0\n",
    "\n",
    "    for x, y, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [train]\"):\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        tr_loss_sum += loss.item() * bs\n",
    "        tr_acc_sum  += acc_from_logits(logits.detach(), y) * bs\n",
    "        tr_n += bs\n",
    "\n",
    "    train_loss = tr_loss_sum / tr_n\n",
    "    train_acc  = tr_acc_sum / tr_n\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    va_loss_sum, va_acc_sum, va_n = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [val]\"):\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            bs = y.size(0)\n",
    "            va_loss_sum += loss.item() * bs\n",
    "            va_acc_sum  += acc_from_logits(logits, y) * bs\n",
    "            va_n += bs\n",
    "\n",
    "    val_loss = va_loss_sum / va_n\n",
    "    val_acc  = va_acc_sum / va_n\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val + 1e-6:\n",
    "        best_val = val_acc\n",
    "        torch.save(model.state_dict(), \"best_aasist_lite.pth\")\n",
    "\n",
    "print(\"Training done. Best Val Acc:\", best_val)\n",
    "print(\"Saved best weights to best_aasist_lite.pth\")\n",
    "\n",
    "# ---------------- TEST + REPORTS + CURVES ----------------\n",
    "model.load_state_dict(torch.load(\"best_aasist_lite.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "probs_all = []\n",
    "embs, emb_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        logits, emb = model(x)\n",
    "        prob = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        pred = int(np.argmax(prob))\n",
    "\n",
    "        y_true.append(int(y.item()))\n",
    "        y_pred.append(pred)\n",
    "        probs_all.append(prob)\n",
    "        embs.append(emb.cpu().numpy()[0])\n",
    "        emb_labels.append(int(y.item()))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "probs_all = np.array(probs_all)\n",
    "embs = np.array(embs)\n",
    "emb_labels = np.array(emb_labels)\n",
    "\n",
    "print(\"\\n================ CLASSIFICATION REPORT ================\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix (AASIST-Lite)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ROC + PR (multi-class OVR)\n",
    "Y_bin = label_binarize(y_true, classes=list(range(NUM_CLASSES)))\n",
    "\n",
    "# ROC\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(Y_bin[:, i], probs_all[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{CLASS_NAMES[i]} (AUC={roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Multi-class ROC Curve (AASIST-Lite)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(fontsize=7, loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_multiclass.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# PR\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(NUM_CLASSES):\n",
    "    prec, rec, _ = precision_recall_curve(Y_bin[:, i], probs_all[:, i])\n",
    "    pr_auc = auc(rec, prec)\n",
    "    plt.plot(rec, prec, label=f\"{CLASS_NAMES[i]} (AUC={pr_auc:.2f})\")\n",
    "plt.title(\"Multi-class Precision-Recall Curve (AASIST-Lite)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(fontsize=7, loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pr_multiclass.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Train/Val curves\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.title(\"Training vs Validation Loss (AASIST-Lite)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_accs, label=\"Train Acc\")\n",
    "plt.plot(val_accs, label=\"Val Acc\")\n",
    "plt.title(\"Training vs Validation Accuracy (AASIST-Lite)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"acc_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Waveform + Spectrogram + Chromagram (one test file)\n",
    "sample_path = test_ds.paths[0] if len(test_ds.paths) else None\n",
    "if sample_path:\n",
    "    y, sr = librosa.load(sample_path, sr=SAMPLE_RATE, mono=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(np.linspace(0, len(y)/sr, len(y)), y)\n",
    "    plt.title(\"Waveform\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"waveform.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)), ref=np.max)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(D, sr=sr, hop_length=HOP_LENGTH, x_axis=\"time\", y_axis=\"hz\")\n",
    "    plt.colorbar(format=\"%+0.0f dB\")\n",
    "    plt.title(\"Spectrogram (dB)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"spectrogram.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, tuning=0.0)\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    librosa.display.specshow(chroma, sr=sr, hop_length=HOP_LENGTH, x_axis=\"time\", y_axis=\"chroma\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Chromagram\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"chromagram.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# PCA / t-SNE embeddings\n",
    "pca = PCA(n_components=2, random_state=RANDOM_SEED)\n",
    "Zp = pca.fit_transform(embs)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(Zp[:, 0], Zp[:, 1], c=emb_labels, s=10)\n",
    "plt.title(\"PCA of AASIST-Lite Embeddings\")\n",
    "plt.colorbar(sc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pca_embeddings.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_SEED, init=\"pca\", learning_rate=\"auto\")\n",
    "Zt = tsne.fit_transform(embs)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(Zt[:, 0], Zt[:, 1], c=emb_labels, s=10)\n",
    "plt.title(\"t-SNE of AASIST-Lite Embeddings\")\n",
    "plt.colorbar(sc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tsne_embeddings.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\"confusion_matrix.png, roc_multiclass.png, pr_multiclass.png, loss_curve.png, acc_curve.png\")\n",
    "print(\"waveform.png, spectrogram.png, chromagram.png, pca_embeddings.png, tsne_embeddings.png\")\n",
    "print(\"Best model: best_aasist_lite.pth\")\n",
    "# ==============================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532bdeff-3b42-4708-b105-88523f32507a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU PyTorch)",
   "language": "python",
   "name": "gpu-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
