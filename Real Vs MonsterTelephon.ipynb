{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85ae282-3f6a-4b9b-887b-d89e2a249c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Barishal Real → train:630  test:135  val:136\n",
      "[DONE] Barishal_monster_telephone → train:630  test:135  val:136\n",
      "[DONE] Chapai Real → train:700  test:150  val:150\n",
      "[DONE] Chapai_monster_telephone → train:700  test:150  val:150\n",
      "[DONE] Chittagong Real → train:1106  test:237  val:237\n",
      "[DONE] Chittagong_monster_telephone → train:1106  test:237  val:237\n",
      "[DONE] Habiganj Real → train:739  test:158  val:160\n",
      "[DONE] Habiganj_monster_telephone → train:739  test:158  val:160\n",
      "[DONE] kishoreganj Real → train:1289  test:276  val:277\n",
      "[DONE] kishoreganj_monster_telephone → train:1289  test:276  val:277\n",
      "[DONE] Kustia Real → train:700  test:150  val:150\n",
      "[DONE] Kustia_monster_telephone → train:700  test:150  val:150\n",
      "[DONE] Naoga Real → train:700  test:150  val:150\n",
      "[DONE] Naoga_monster_telephone → train:700  test:150  val:150\n",
      "[DONE] Narail Real → train:1169  test:250  val:252\n",
      "[DONE] Narail_monster_telephone → train:1169  test:250  val:252\n",
      "[DONE] Narsingdi Real → train:863  test:185  val:186\n",
      "[DONE] Narsingdi_monster_telephone → train:863  test:185  val:186\n",
      "[DONE] pabna Real → train:697  test:149  val:151\n",
      "[DONE] pabna_monster_telephone → train:697  test:149  val:151\n",
      "[DONE] Rajshahi Real → train:675  test:144  val:146\n",
      "[DONE] Rajshahi_monster_telephone → train:675  test:144  val:146\n",
      "[DONE] Rangpur Real → train:817  test:175  val:176\n",
      "[DONE] Rangpur_monster_telephone → train:817  test:175  val:176\n",
      "[DONE] Sandwip Real → train:824  test:176  val:178\n",
      "[DONE] Sandwip_monster_telephone → train:824  test:176  val:178\n",
      "[DONE] Sylhet Real → train:2281  test:488  val:490\n",
      "[DONE] Sylhet_monster_telephone → train:2281  test:488  val:490\n",
      "[DONE] Tangail Real → train:782  test:167  val:169\n",
      "[DONE] Tangail_monster_telephone → train:782  test:167  val:169\n",
      "\n",
      "Dataset successfully split into Train/Test/Val!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set paths\n",
    "dataset_path = r\"D:\\Real Vs Monster_Telephon\"\n",
    "output_path = r\"D:\\Real Vs Monster_Telephon_Split\"\n",
    "\n",
    "# Split ratios\n",
    "train_ratio = 0.70\n",
    "test_ratio = 0.15\n",
    "val_ratio = 0.15\n",
    "\n",
    "# Create output directories\n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    os.makedirs(os.path.join(output_path, split), exist_ok=True)\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Create class folders inside train/test/val\n",
    "    for split in [\"train\", \"test\", \"val\"]:\n",
    "        os.makedirs(os.path.join(output_path, split, class_name), exist_ok=True)\n",
    "\n",
    "    # List and shuffle files\n",
    "    files = os.listdir(class_path)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    total = len(files)\n",
    "    train_end = int(total * train_ratio)\n",
    "    test_end = train_end + int(total * test_ratio)\n",
    "\n",
    "    train_files = files[:train_end]\n",
    "    test_files = files[train_end:test_end]\n",
    "    val_files = files[test_end:]\n",
    "\n",
    "    # Copy files to split folders\n",
    "    for f in train_files:\n",
    "        shutil.copy(os.path.join(class_path, f),\n",
    "                    os.path.join(output_path, \"train\", class_name))\n",
    "\n",
    "    for f in test_files:\n",
    "        shutil.copy(os.path.join(class_path, f),\n",
    "                    os.path.join(output_path, \"test\", class_name))\n",
    "\n",
    "    for f in val_files:\n",
    "        shutil.copy(os.path.join(class_path, f),\n",
    "                    os.path.join(output_path, \"val\", class_name))\n",
    "\n",
    "    print(f\"[DONE] {class_name} → train:{len(train_files)}  test:{len(test_files)}  val:{len(val_files)}\")\n",
    "\n",
    "print(\"\\nDataset successfully split into Train/Test/Val!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e66a5f9-422e-4435-91d4-b40d689a6d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Classes: 30\n",
      "['Barishal Real', 'Barishal_monster_telephone', 'Chapai Real', 'Chapai_monster_telephone', 'Chittagong Real', 'Chittagong_monster_telephone', 'Habiganj Real', 'Habiganj_monster_telephone', 'Kustia Real', 'Kustia_monster_telephone', 'Naoga Real', 'Naoga_monster_telephone', 'Narail Real', 'Narail_monster_telephone', 'Narsingdi Real', 'Narsingdi_monster_telephone', 'Rajshahi Real', 'Rajshahi_monster_telephone', 'Rangpur Real', 'Rangpur_monster_telephone', 'Sandwip Real', 'Sandwip_monster_telephone', 'Sylhet Real', 'Sylhet_monster_telephone', 'Tangail Real', 'Tangail_monster_telephone', 'kishoreganj Real', 'kishoreganj_monster_telephone', 'pabna Real', 'pabna_monster_telephone']\n",
      "train set: 27944 files\n",
      "val set: 6016 files\n",
      "test set: 5980 files\n",
      "AASISTLite(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (proj): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (temporal): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AttentivePool(\n",
      "    (attn): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "Epoch 1/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [26:39<00:00,  1.09it/s]\n",
      "Epoch 1/30 [val]: 100%|██████████████████████████████████████████████████████████████| 376/376 [04:33<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 1.5016 Acc 0.4509 | Val Loss 1.1170 Acc 0.6059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [29:48<00:00,  1.02s/it]\n",
      "Epoch 2/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 151.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss 0.9620 Acc 0.6243 | Val Loss 0.9131 Acc 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [32:05<00:00,  1.10s/it]\n",
      "Epoch 3/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 131.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss 0.7788 Acc 0.6950 | Val Loss 0.7188 Acc 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [29:55<00:00,  1.03s/it]\n",
      "Epoch 4/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 139.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss 0.6668 Acc 0.7325 | Val Loss 0.6501 Acc 0.7693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [30:23<00:00,  1.04s/it]\n",
      "Epoch 5/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 138.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss 0.5897 Acc 0.7652 | Val Loss 0.5777 Acc 0.7934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [30:37<00:00,  1.05s/it]\n",
      "Epoch 6/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 147.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss 0.5169 Acc 0.7914 | Val Loss 0.4959 Acc 0.8258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [28:42<00:00,  1.01it/s]\n",
      "Epoch 7/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 150.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss 0.4747 Acc 0.8071 | Val Loss 0.4557 Acc 0.8391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [30:13<00:00,  1.04s/it]\n",
      "Epoch 8/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 154.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss 0.4168 Acc 0.8290 | Val Loss 0.4615 Acc 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [train]: 100%|██████████████████████████████████████████████████████████| 1747/1747 [33:08<00:00,  1.14s/it]\n",
      "Epoch 9/30 [val]: 100%|█████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 147.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss 0.3830 Acc 0.8449 | Val Loss 0.4594 Acc 0.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [34:58<00:00,  1.20s/it]\n",
      "Epoch 10/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 150.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss 0.3562 Acc 0.8557 | Val Loss 0.3731 Acc 0.8753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [31:20<00:00,  1.08s/it]\n",
      "Epoch 11/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 151.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss 0.3234 Acc 0.8688 | Val Loss 0.3750 Acc 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [31:34<00:00,  1.08s/it]\n",
      "Epoch 12/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 153.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss 0.3159 Acc 0.8747 | Val Loss 0.3854 Acc 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [20:59<00:00,  1.39it/s]\n",
      "Epoch 13/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 150.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss 0.2882 Acc 0.8855 | Val Loss 0.3657 Acc 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [24:23<00:00,  1.19it/s]\n",
      "Epoch 14/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 144.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss 0.2678 Acc 0.8910 | Val Loss 0.3664 Acc 0.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [29:34<00:00,  1.02s/it]\n",
      "Epoch 15/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 153.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss 0.2501 Acc 0.8995 | Val Loss 0.3707 Acc 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [23:32<00:00,  1.24it/s]\n",
      "Epoch 16/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 153.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss 0.2316 Acc 0.9076 | Val Loss 0.3732 Acc 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [22:53<00:00,  1.27it/s]\n",
      "Epoch 17/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 148.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss 0.2203 Acc 0.9113 | Val Loss 0.3851 Acc 0.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [20:50<00:00,  1.40it/s]\n",
      "Epoch 18/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 149.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss 0.2083 Acc 0.9166 | Val Loss 0.3612 Acc 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [23:45<00:00,  1.23it/s]\n",
      "Epoch 19/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 147.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss 0.1991 Acc 0.9202 | Val Loss 0.3821 Acc 0.8935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [24:29<00:00,  1.19it/s]\n",
      "Epoch 20/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 147.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss 0.1824 Acc 0.9266 | Val Loss 0.3429 Acc 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [21:23<00:00,  1.36it/s]\n",
      "Epoch 21/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 147.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss 0.1791 Acc 0.9291 | Val Loss 0.3658 Acc 0.8961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [25:41<00:00,  1.13it/s]\n",
      "Epoch 22/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 154.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss 0.1741 Acc 0.9325 | Val Loss 0.3179 Acc 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [25:15<00:00,  1.15it/s]\n",
      "Epoch 23/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 150.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss 0.1604 Acc 0.9368 | Val Loss 0.3476 Acc 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [23:51<00:00,  1.22it/s]\n",
      "Epoch 24/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 155.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss 0.1520 Acc 0.9387 | Val Loss 0.3079 Acc 0.9195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [43:42<00:00,  1.50s/it]\n",
      "Epoch 25/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:03<00:00, 108.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss 0.1552 Acc 0.9422 | Val Loss 0.3695 Acc 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [50:55<00:00,  1.75s/it]\n",
      "Epoch 26/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:03<00:00, 111.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss 0.1435 Acc 0.9453 | Val Loss 0.3338 Acc 0.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [train]: 100%|███████████████████████████████████████████████████████| 1747/1747 [6:54:01<00:00, 14.22s/it]\n",
      "Epoch 27/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 150.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss 0.1375 Acc 0.9479 | Val Loss 0.3371 Acc 0.9174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [30:19<00:00,  1.04s/it]\n",
      "Epoch 28/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 141.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss 0.0769 Acc 0.9694 | Val Loss 0.3201 Acc 0.9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [23:47<00:00,  1.22it/s]\n",
      "Epoch 29/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 148.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss 0.0646 Acc 0.9735 | Val Loss 0.3179 Acc 0.9317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [train]: 100%|█████████████████████████████████████████████████████████| 1747/1747 [20:17<00:00,  1.44it/s]\n",
      "Epoch 30/30 [val]: 100%|████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 143.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss 0.0621 Acc 0.9752 | Val Loss 0.3298 Acc 0.9307\n",
      "Training done. Best Val Acc: 0.9316821808510638\n",
      "Saved best weights to best_aasist_lite.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_23796\\2623449860.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_aasist_lite.pth\", map_location=device))\n",
      "Testing: 100%|█████████████████████████████████████████████████████████████████████| 5980/5980 [06:07<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CLASSIFICATION REPORT ================\n",
      "\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "                Barishal Real     0.9470    0.9259    0.9363       135\n",
      "   Barishal_monster_telephone     0.8235    0.8296    0.8266       135\n",
      "                  Chapai Real     0.9934    1.0000    0.9967       150\n",
      "     Chapai_monster_telephone     0.9933    0.9933    0.9933       150\n",
      "              Chittagong Real     0.9309    0.9662    0.9482       237\n",
      " Chittagong_monster_telephone     0.8051    0.9241    0.8605       237\n",
      "                Habiganj Real     0.8111    0.9241    0.8639       158\n",
      "   Habiganj_monster_telephone     0.8261    0.7215    0.7703       158\n",
      "                  Kustia Real     1.0000    1.0000    1.0000       150\n",
      "     Kustia_monster_telephone     0.9933    0.9933    0.9933       150\n",
      "                   Naoga Real     1.0000    1.0000    1.0000       150\n",
      "      Naoga_monster_telephone     0.9933    0.9867    0.9900       150\n",
      "                  Narail Real     0.9430    0.9920    0.9669       250\n",
      "     Narail_monster_telephone     0.8740    0.8880    0.8810       250\n",
      "               Narsingdi Real     0.9362    0.9514    0.9437       185\n",
      "  Narsingdi_monster_telephone     0.9209    0.8811    0.9006       185\n",
      "                Rajshahi Real     0.9931    0.9931    0.9931       144\n",
      "   Rajshahi_monster_telephone     1.0000    1.0000    1.0000       144\n",
      "                 Rangpur Real     0.9706    0.9429    0.9565       175\n",
      "    Rangpur_monster_telephone     0.9213    0.9371    0.9292       175\n",
      "                 Sandwip Real     0.9882    0.9545    0.9711       176\n",
      "    Sandwip_monster_telephone     0.8820    0.8920    0.8870       176\n",
      "                  Sylhet Real     0.9673    0.9098    0.9377       488\n",
      "     Sylhet_monster_telephone     0.8905    0.8668    0.8785       488\n",
      "                 Tangail Real     0.9938    0.9521    0.9725       167\n",
      "    Tangail_monster_telephone     0.9030    0.8922    0.8976       167\n",
      "             kishoreganj Real     0.9534    0.9638    0.9586       276\n",
      "kishoreganj_monster_telephone     0.9007    0.8877    0.8942       276\n",
      "                   pabna Real     1.0000    0.9933    0.9966       149\n",
      "      pabna_monster_telephone     0.9737    0.9933    0.9834       149\n",
      "\n",
      "                     accuracy                         0.9319      5980\n",
      "                    macro avg     0.9376    0.9385    0.9376      5980\n",
      "                 weighted avg     0.9330    0.9319    0.9319      5980\n",
      "\n",
      "\n",
      "Saved figures:\n",
      "confusion_matrix.png, roc_multiclass.png, pr_multiclass.png, loss_curve.png, acc_curve.png\n",
      "waveform.png, spectrogram.png, chromagram.png, pca_embeddings.png, tsne_embeddings.png\n",
      "Best model: best_aasist_lite.pth\n"
     ]
    }
   ],
   "source": [
    "# ===================== AASIST-Lite (Spectro-Temporal) FULL TRAIN+EVAL CODE =====================\n",
    "# Works with your folder structure:\n",
    "# D:\\RealVsMonster_Split\\train\\<class>\\audio.*\n",
    "# D:\\RealVsMonster_Split\\val\\<class>\\audio.*\n",
    "# D:\\RealVsMonster_Split\\test\\<class>\\audio.*\n",
    "#\n",
    "# Output:\n",
    "# - best_aasist_lite.pth\n",
    "# - confusion_matrix.png\n",
    "# - roc_multiclass.png\n",
    "# - pr_multiclass.png\n",
    "# - loss_curve.png\n",
    "# - acc_curve.png\n",
    "# - waveform.png / spectrogram.png / chromagram.png\n",
    "# - pca_embeddings.png / tsne_embeddings.png\n",
    "# - classification report printed in console\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATASET_ROOT = r\"D:\\Real Vs Monster_Telephon_Split\"\n",
    "SAMPLE_RATE  = 16000\n",
    "\n",
    "# Feature: 2-channel -> [LogMel, Linear-Fbank(log)]  (spectral)\n",
    "N_MELS       = 64\n",
    "N_LINFB      = 64\n",
    "N_FFT        = 1024\n",
    "HOP_LENGTH   = 256\n",
    "MAX_FRAMES   = 256\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE   = 16\n",
    "EPOCHS       = 30\n",
    "LR           = 2e-4\n",
    "RANDOM_SEED  = 42\n",
    "\n",
    "# SpecAugment\n",
    "USE_SPECAUG      = True\n",
    "TIME_MASK_PARAM  = 24\n",
    "FREQ_MASK_PARAM  = 6\n",
    "\n",
    "# Audio safety\n",
    "MIN_AUDIO_SAMPLES = 2048\n",
    "MIN_RMS = 1e-4\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------- CLASS NAMES ----------------\n",
    "train_base = os.path.join(DATASET_ROOT, \"train\")\n",
    "CLASS_NAMES = sorted([d for d in os.listdir(train_base) if os.path.isdir(os.path.join(train_base, d))])\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(\"Classes:\", NUM_CLASSES)\n",
    "print(CLASS_NAMES)\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def pad_trunc_2d(X, max_frames):\n",
    "    # X: (F, T)\n",
    "    if X.shape[1] < max_frames:\n",
    "        pad = np.zeros((X.shape[0], max_frames - X.shape[1]), dtype=np.float32)\n",
    "        X = np.concatenate([X, pad], axis=1)\n",
    "    else:\n",
    "        X = X[:, :max_frames]\n",
    "    return X\n",
    "\n",
    "def zscore_norm(X, eps=1e-6):\n",
    "    mu = float(X.mean())\n",
    "    std = float(X.std())\n",
    "    return (X - mu) / (std + eps)\n",
    "\n",
    "def safe_load_and_trim(path):\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
    "    y, _ = librosa.effects.trim(y, top_db=30)\n",
    "\n",
    "    if y is None or len(y) < MIN_AUDIO_SAMPLES:\n",
    "        return None, sr\n",
    "\n",
    "    rms = float(np.sqrt(np.mean(y**2) + 1e-12))\n",
    "    if rms < MIN_RMS:\n",
    "        return None, sr\n",
    "\n",
    "    return y, sr\n",
    "\n",
    "# ---------------- FEATURE EXTRACTION ----------------\n",
    "def extract_logmel(y, sr):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH, power=2.0\n",
    "    )\n",
    "    mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel = zscore_norm(mel).astype(np.float32)\n",
    "    mel = pad_trunc_2d(mel, MAX_FRAMES)\n",
    "    return mel  # (64, T)\n",
    "\n",
    "def extract_log_linear_fbank(y, sr):\n",
    "    \"\"\"\n",
    "    Manual linear-frequency filterbank energies (log)  (no librosa.filters.linear dependency)\n",
    "    \"\"\"\n",
    "    S = np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH))**2  # (F, T)\n",
    "    F_bins = S.shape[0]\n",
    "\n",
    "    freqs = np.linspace(0, sr/2, F_bins, dtype=np.float32)\n",
    "    edges = np.linspace(0, sr/2, N_LINFB + 2, dtype=np.float32)\n",
    "\n",
    "    fb = np.zeros((N_LINFB, F_bins), dtype=np.float32)\n",
    "    for m in range(N_LINFB):\n",
    "        f_left, f_center, f_right = edges[m], edges[m+1], edges[m+2]\n",
    "        left  = (freqs - f_left) / (f_center - f_left + 1e-9)\n",
    "        right = (f_right - freqs) / (f_right - f_center + 1e-9)\n",
    "        fb[m] = np.maximum(0.0, np.minimum(left, right))\n",
    "\n",
    "    E = np.dot(fb, S) + 1e-8\n",
    "    E = np.log(E)\n",
    "\n",
    "    E = zscore_norm(E).astype(np.float32)\n",
    "    E = pad_trunc_2d(E, MAX_FRAMES)\n",
    "    return E  # (64, T)\n",
    "\n",
    "def extract_features(path):\n",
    "    y, sr = safe_load_and_trim(path)\n",
    "    if y is None:\n",
    "        mel = np.zeros((N_MELS, MAX_FRAMES), dtype=np.float32)\n",
    "        lfb = np.zeros((N_LINFB, MAX_FRAMES), dtype=np.float32)\n",
    "    else:\n",
    "        mel = extract_logmel(y, sr)\n",
    "        lfb = extract_log_linear_fbank(y, sr)\n",
    "    X = np.stack([mel, lfb], axis=0).astype(np.float32)  # (2, 64, T)\n",
    "    return X\n",
    "\n",
    "# ---------------- SPECAUGMENT ----------------\n",
    "def spec_augment(x, time_mask_param=24, freq_mask_param=6):\n",
    "    # x: torch tensor (C,F,T) ; masks apply all channels\n",
    "    if not USE_SPECAUG:\n",
    "        return x\n",
    "    C, F, T = x.shape\n",
    "\n",
    "    f = random.randint(0, min(freq_mask_param, F))\n",
    "    f0 = random.randint(0, max(0, F - f))\n",
    "    if f > 0:\n",
    "        x[:, f0:f0+f, :] = 0\n",
    "\n",
    "    t = random.randint(0, min(time_mask_param, T))\n",
    "    t0 = random.randint(0, max(0, T - t))\n",
    "    if t > 0:\n",
    "        x[:, :, t0:t0+t] = 0\n",
    "\n",
    "    return x\n",
    "\n",
    "# ---------------- DATASET ----------------\n",
    "class SpecDataset(Dataset):\n",
    "    def __init__(self, root, split):\n",
    "        base = os.path.join(root, split)\n",
    "        self.split = split\n",
    "        self.paths, self.labels = [], []\n",
    "        self.cls_to_idx = {c: i for i, c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "        for cls in CLASS_NAMES:\n",
    "            folder = os.path.join(base, cls)\n",
    "            if not os.path.isdir(folder):\n",
    "                continue\n",
    "            for f in os.listdir(folder):\n",
    "                if f.lower().endswith((\".mp3\", \".wav\", \".ogg\", \".flac\", \".m4a\")):\n",
    "                    self.paths.append(os.path.join(folder, f))\n",
    "                    self.labels.append(self.cls_to_idx[cls])\n",
    "\n",
    "        print(f\"{split} set: {len(self.paths)} files\")\n",
    "        self.cache = {}  # cache val/test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.split != \"train\" and path in self.cache:\n",
    "            feat = self.cache[path]\n",
    "        else:\n",
    "            feat = extract_features(path)\n",
    "            if self.split != \"train\":\n",
    "                self.cache[path] = feat\n",
    "\n",
    "        x = torch.tensor(feat)  # (2,64,T)\n",
    "        if self.split == \"train\":\n",
    "            x = spec_augment(x, TIME_MASK_PARAM, FREQ_MASK_PARAM)\n",
    "\n",
    "        return x, torch.tensor(label, dtype=torch.long), path\n",
    "\n",
    "train_ds = SpecDataset(DATASET_ROOT, \"train\")\n",
    "val_ds   = SpecDataset(DATASET_ROOT, \"val\")\n",
    "test_ds  = SpecDataset(DATASET_ROOT, \"test\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=1,          shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ---------------- MODEL (AASIST-Lite): CNN(spectral) + Transformer(temporal) + AttnPool ----------------\n",
    "class AttentivePool(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(d, d//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d//2, 1)\n",
    "        )\n",
    "    def forward(self, x):   # (B,T,D)\n",
    "        w = torch.softmax(self.attn(x), dim=1)  # (B,T,1)\n",
    "        return (w * x).sum(dim=1)               # (B,D)\n",
    "\n",
    "class AASISTLite(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: (B, 2, 64, T)\n",
    "    CNN -> spectral patterns\n",
    "    Transformer -> temporal patterns\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, d_model=256, nhead=4, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),  # F/2, T/2\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),  # F/4, T/4\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),  # F/8, T/8\n",
    "        )\n",
    "\n",
    "        f_after = N_MELS // 8  # 64 -> 8\n",
    "        self.proj = nn.Linear(128 * f_after, d_model)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, batch_first=True, activation=\"gelu\", norm_first=True\n",
    "        )\n",
    "        self.temporal = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        self.pool = AttentivePool(d_model)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.cnn(x)                      # (B,128,F',T')\n",
    "        B, C, F, T = z.shape\n",
    "        z = z.permute(0, 3, 1, 2).contiguous()  # (B,T,C,F)\n",
    "        z = z.view(B, T, C*F)                   # (B,T,128*F')\n",
    "        z = self.proj(z)                        # (B,T,d_model)\n",
    "\n",
    "        z = self.temporal(z)                    # (B,T,d_model)  (temporal features)\n",
    "        emb = self.pool(z)                      # (B,d_model)\n",
    "        logits = self.head(emb)                 # (B,num_classes)\n",
    "        return logits, emb\n",
    "\n",
    "model = AASISTLite(num_classes=NUM_CLASSES).to(device)\n",
    "print(model)\n",
    "\n",
    "# ---------------- LOSS/OPT ----------------\n",
    "counts = np.bincount(train_ds.labels, minlength=NUM_CLASSES).astype(np.float32)\n",
    "w = (counts.sum() / (counts + 1e-6))\n",
    "w = w / w.mean()\n",
    "class_weights = torch.tensor(w, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "use_amp = (device.type == \"cuda\")\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "\n",
    "def acc_from_logits(logits, y):\n",
    "    return (torch.argmax(logits, 1) == y).float().mean().item()\n",
    "\n",
    "# ---------------- TRAIN ----------------\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "best_val = -1.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    tr_loss_sum, tr_acc_sum, tr_n = 0.0, 0.0, 0\n",
    "\n",
    "    for x, y, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [train]\"):\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        tr_loss_sum += loss.item() * bs\n",
    "        tr_acc_sum  += acc_from_logits(logits.detach(), y) * bs\n",
    "        tr_n += bs\n",
    "\n",
    "    train_loss = tr_loss_sum / tr_n\n",
    "    train_acc  = tr_acc_sum / tr_n\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    va_loss_sum, va_acc_sum, va_n = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [val]\"):\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            bs = y.size(0)\n",
    "            va_loss_sum += loss.item() * bs\n",
    "            va_acc_sum  += acc_from_logits(logits, y) * bs\n",
    "            va_n += bs\n",
    "\n",
    "    val_loss = va_loss_sum / va_n\n",
    "    val_acc  = va_acc_sum / va_n\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val + 1e-6:\n",
    "        best_val = val_acc\n",
    "        torch.save(model.state_dict(), \"best_aasist_lite.pth\")\n",
    "\n",
    "print(\"Training done. Best Val Acc:\", best_val)\n",
    "print(\"Saved best weights to best_aasist_lite.pth\")\n",
    "\n",
    "# ---------------- TEST + REPORTS + CURVES ----------------\n",
    "model.load_state_dict(torch.load(\"best_aasist_lite.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "probs_all = []\n",
    "embs, emb_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        logits, emb = model(x)\n",
    "        prob = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        pred = int(np.argmax(prob))\n",
    "\n",
    "        y_true.append(int(y.item()))\n",
    "        y_pred.append(pred)\n",
    "        probs_all.append(prob)\n",
    "        embs.append(emb.cpu().numpy()[0])\n",
    "        emb_labels.append(int(y.item()))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "probs_all = np.array(probs_all)\n",
    "embs = np.array(embs)\n",
    "emb_labels = np.array(emb_labels)\n",
    "\n",
    "print(\"\\n================ CLASSIFICATION REPORT ================\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix (AASIST-Lite)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ROC + PR (multi-class OVR)\n",
    "Y_bin = label_binarize(y_true, classes=list(range(NUM_CLASSES)))\n",
    "\n",
    "# ROC\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(Y_bin[:, i], probs_all[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{CLASS_NAMES[i]} (AUC={roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Multi-class ROC Curve (AASIST-Lite)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(fontsize=7, loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_multiclass.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# PR\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(NUM_CLASSES):\n",
    "    prec, rec, _ = precision_recall_curve(Y_bin[:, i], probs_all[:, i])\n",
    "    pr_auc = auc(rec, prec)\n",
    "    plt.plot(rec, prec, label=f\"{CLASS_NAMES[i]} (AUC={pr_auc:.2f})\")\n",
    "plt.title(\"Multi-class Precision-Recall Curve (AASIST-Lite)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(fontsize=7, loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pr_multiclass.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Train/Val curves\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.title(\"Training vs Validation Loss (AASIST-Lite)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_accs, label=\"Train Acc\")\n",
    "plt.plot(val_accs, label=\"Val Acc\")\n",
    "plt.title(\"Training vs Validation Accuracy (AASIST-Lite)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"acc_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Waveform + Spectrogram + Chromagram (one test file)\n",
    "sample_path = test_ds.paths[0] if len(test_ds.paths) else None\n",
    "if sample_path:\n",
    "    y, sr = librosa.load(sample_path, sr=SAMPLE_RATE, mono=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(np.linspace(0, len(y)/sr, len(y)), y)\n",
    "    plt.title(\"Waveform\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"waveform.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)), ref=np.max)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(D, sr=sr, hop_length=HOP_LENGTH, x_axis=\"time\", y_axis=\"hz\")\n",
    "    plt.colorbar(format=\"%+0.0f dB\")\n",
    "    plt.title(\"Spectrogram (dB)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"spectrogram.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, tuning=0.0)\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    librosa.display.specshow(chroma, sr=sr, hop_length=HOP_LENGTH, x_axis=\"time\", y_axis=\"chroma\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Chromagram\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"chromagram.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# PCA / t-SNE embeddings\n",
    "pca = PCA(n_components=2, random_state=RANDOM_SEED)\n",
    "Zp = pca.fit_transform(embs)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(Zp[:, 0], Zp[:, 1], c=emb_labels, s=10)\n",
    "plt.title(\"PCA of AASIST-Lite Embeddings\")\n",
    "plt.colorbar(sc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pca_embeddings.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_SEED, init=\"pca\", learning_rate=\"auto\")\n",
    "Zt = tsne.fit_transform(embs)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(Zt[:, 0], Zt[:, 1], c=emb_labels, s=10)\n",
    "plt.title(\"t-SNE of AASIST-Lite Embeddings\")\n",
    "plt.colorbar(sc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tsne_embeddings.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\"confusion_matrix.png, roc_multiclass.png, pr_multiclass.png, loss_curve.png, acc_curve.png\")\n",
    "print(\"waveform.png, spectrogram.png, chromagram.png, pca_embeddings.png, tsne_embeddings.png\")\n",
    "print(\"Best model: best_aasist_lite.pth\")\n",
    "# ==============================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067d0e3-624a-4a8a-ab99-8c9d83032ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU PyTorch)",
   "language": "python",
   "name": "gpu-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
